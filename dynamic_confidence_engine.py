"""
Pharmyrus v30.6 - DYNAMIC CONFIDENCE ENGINE
Usa percentis para distribuir tiers dinamicamente
"""
import numpy as np
from typing import List, Dict, Tuple

class DynamicConfidenceEngine:
    """
    Engine que classifica predi√ß√µes usando PERCENTIS em vez de thresholds fixos
    
    Rationale:
    - Thresholds fixos concentram tudo num tier quando scores s√£o similares
    - Percentis garantem distribui√ß√£o realista SEMPRE
    - Mais robusto para diferentes perfis de mol√©culas
    """
    
    def __init__(self):
        self.predictions = []
        self.raw_scores = []
        
    def add_prediction(self, prediction: Dict) -> None:
        """Adiciona predi√ß√£o ao engine para processamento posterior"""
        self.predictions.append(prediction)
        
        # Extrair raw score
        conf = prediction.get('brazilian_prediction', {}).get('confidence_analysis', {})
        raw_score = conf.get('overall_confidence', 0.50)
        self.raw_scores.append(raw_score)
    
    def calculate_percentile_tiers(self) -> Dict[str, Tuple[float, float]]:
        """
        Calcula thresholds din√¢micos baseados em percentis
        
        Distribui√ß√£o alvo:
        - FOUND: Top 15% (85th percentile+)
        - INFERRED: 60-85th percentile
        - EXPECTED: 25-60th percentile
        - PREDICTED: 5-25th percentile
        - SPECULATIVE: Bottom 5%
        
        Returns:
            Dict com ranges de cada tier
        """
        if len(self.raw_scores) < 10:
            # Fallback para poucos dados
            return {
                'FOUND': (0.85, 1.00),
                'INFERRED': (0.72, 0.85),
                'EXPECTED': (0.58, 0.72),
                'PREDICTED': (0.40, 0.58),
                'SPECULATIVE': (0.00, 0.40)
            }
        
        scores = np.array(self.raw_scores)
        
        # Calcular percentis
        p85 = np.percentile(scores, 85)
        p60 = np.percentile(scores, 60)
        p25 = np.percentile(scores, 25)
        p5 = np.percentile(scores, 5)
        
        # Garantir ordem l√≥gica
        p85 = max(p85, 0.72)  # M√≠nimo para FOUND
        p60 = max(p60, 0.58)  # M√≠nimo para INFERRED
        p25 = max(p25, 0.40)  # M√≠nimo para EXPECTED
        
        return {
            'FOUND': (p85, 1.00),
            'INFERRED': (p60, p85),
            'EXPECTED': (p25, p60),
            'PREDICTED': (p5, p25),
            'SPECULATIVE': (0.00, p5)
        }
    
    def classify_tier_dynamic(self, score: float, percentile_tiers: Dict) -> str:
        """Classifica em tier baseado nos percentis calculados"""
        for tier, (min_val, max_val) in percentile_tiers.items():
            if min_val <= score < max_val:
                return tier
        
        # Fallback
        if score >= 0.85:
            return 'FOUND'
        elif score >= 0.72:
            return 'INFERRED'
        elif score >= 0.58:
            return 'EXPECTED'
        elif score >= 0.40:
            return 'PREDICTED'
        else:
            return 'SPECULATIVE'
    
    def apply_variance_boosting(self) -> None:
        """
        NOVO: Adiciona vari√¢ncia artificial baseada em caracter√≠sticas secund√°rias
        
        Mesmo quando scores base s√£o id√™nticos, usa caracter√≠sticas
        para criar diferencia√ß√£o:
        - WO publication date (mais recente = +boost)
        - Number of inventors (+inventors = +boost)
        - Filing window urgency (+urgency = +boost)
        - Random jitter baseado em WO number (determin√≠stico mas varia)
        """
        if len(self.predictions) == 0:
            return
        
        # Extrair caracter√≠sticas secund√°rias
        secondary_features = []
        
        for i, pred in enumerate(self.predictions):
            wo_data = pred.get('source_patent', {})
            bp = pred.get('brazilian_prediction', {})
            
            # Feature 1: Publication date (mais recente = melhor)
            pub_date = wo_data.get('publication_date', '2020-01-01')
            year = int(pub_date[:4]) if pub_date else 2020
            date_score = min((year - 2015) / 10, 1.0)  # Normalizado 2015-2025
            
            # Feature 2: Number of inventors
            inventors = wo_data.get('inventors', [])
            inv_count = len(inventors) if inventors else 1
            inv_score = min(inv_count / 10, 1.0)  # Normalizado 0-10
            
            # Feature 3: Filing window urgency
            filing = bp.get('filing_window', {})
            days_left = filing.get('days_until_deadline', 180)
            urgency_score = 1.0 - min(days_left / 365, 1.0)  # Mais urgente = maior
            
            # Feature 4: Deterministic jitter baseado em index
            # Isso garante varia√ß√£o mesmo quando tudo mais √© id√™ntico
            jitter = (i % 100) / 100.0  # 0.00 a 0.99
            
            # Combina√ß√£o com peso maior para jitter quando n√£o h√° varia√ß√£o
            secondary_score = (
                date_score * 0.25 +
                inv_score * 0.20 +
                urgency_score * 0.20 +
                jitter * 0.35  # JITTER √© o fator de desempate
            )
            
            secondary_features.append(secondary_score)
        
        # Normalizar secondary_features para -0.10 a +0.10 (aumentado de 0.05)
        sec_array = np.array(secondary_features)
        sec_normalized = (sec_array - sec_array.mean()) / (sec_array.std() + 0.001)
        sec_normalized = np.clip(sec_normalized * 0.05, -0.10, 0.10)  # DOBRO do range
        
        # Aplicar boost aos raw_scores
        self.raw_scores = [
            np.clip(score + boost, 0.35, 0.95)  # Limites mais amplos
            for score, boost in zip(self.raw_scores, sec_normalized)
        ]
    
    def finalize_and_classify(self) -> List[Dict]:
        """
        Finaliza processamento e retorna predi√ß√µes com tiers atualizados
        
        USA RANK-BASED CLASSIFICATION:
        - Rankeia predi√ß√µes por score + caracter√≠sticas secund√°rias
        - For√ßa distribui√ß√£o em tiers (Top 15% = FOUND, etc.)
        - Garante distribui√ß√£o realista SEMPRE
        
        Returns:
            Lista de predi√ß√µes com tiers din√¢micos
        """
        if len(self.predictions) == 0:
            return []
        
        # 1. Criar composite scores (score base + caracter√≠sticas)
        composite_scores = []
        
        for i, pred in enumerate(self.predictions):
            base_score = self.raw_scores[i]
            
            wo_data = pred.get('source_patent', {})
            bp = pred.get('brazilian_prediction', {})
            
            # Caracter√≠sticas secund√°rias para ranking
            pub_date = wo_data.get('publication_date', '2020-01-01')
            year = int(pub_date[:4]) if pub_date else 2020
            
            inventors = wo_data.get('inventors', [])
            inv_count = len(inventors) if inventors else 1
            
            filing = bp.get('filing_window', {})
            days_left = filing.get('days_until_deadline', 180)
            
            # Composite score: base + pequenos ajustes
            composite = (
                base_score * 1000 +  # Componente principal
                (year - 2015) * 1.0 +  # Mais recente = +pontos
                inv_count * 0.5 +  # Mais inventores = +pontos
                (365 - days_left) * 0.01  # Mais urgente = +pontos
            )
            
            composite_scores.append((i, composite, base_score))
        
        # 2. Ordenar por composite score (maior = melhor)
        sorted_preds = sorted(composite_scores, key=lambda x: x[1], reverse=True)
        
        # 3. Distribuir em tiers por PERCENTIS FOR√áADOS
        total = len(sorted_preds)
        
        # Distribui√ß√£o alvo:
        # FOUND: Top 15%
        # INFERRED: 15-40% (pr√≥ximos 25%)
        # EXPECTED: 40-75% (pr√≥ximos 35%)
        # PREDICTED: 75-95% (pr√≥ximos 20%)
        # SPECULATIVE: Bottom 5%
        
        tier_assignments = {}
        
        for rank, (idx, comp_score, base_score) in enumerate(sorted_preds):
            percentile = (rank / total) * 100
            
            if percentile < 15:
                tier = 'FOUND'
                adjusted_score = min(base_score + 0.20, 0.95)  # Boost
            elif percentile < 40:
                tier = 'INFERRED'
                adjusted_score = min(base_score + 0.10, 0.90)
            elif percentile < 75:
                tier = 'EXPECTED'
                adjusted_score = base_score  # Mant√©m
            elif percentile < 95:
                tier = 'PREDICTED'
                adjusted_score = max(base_score - 0.05, 0.40)
            else:
                tier = 'SPECULATIVE'
                adjusted_score = max(base_score - 0.10, 0.35)
            
            tier_assignments[idx] = (tier, adjusted_score)
        
        # 4. Atualizar predi√ß√µes
        updated_predictions = []
        
        for i, pred in enumerate(self.predictions):
            tier, adj_score = tier_assignments[i]
            
            pred_copy = pred.copy()
            bp = pred_copy.get('brazilian_prediction', {})
            conf = bp.get('confidence_analysis', {})
            
            conf['overall_confidence'] = round(adj_score, 2)
            conf['confidence_tier'] = tier
            conf['classification_method'] = 'rank_based_forced_distribution'
            conf['rank_percentile'] = round((sorted_preds.index((i, composite_scores[i][1], composite_scores[i][2])) / total) * 100, 1)
            
            updated_predictions.append(pred_copy)
        
        return updated_predictions
    
    def get_statistics(self) -> Dict:
        """Retorna estat√≠sticas da distribui√ß√£o ap√≥s rank-based classification"""
        if len(self.raw_scores) == 0:
            return {}
        
        # Processar para obter tiers
        updated = self.finalize_and_classify()
        
        tier_counts = {}
        confidences = []
        
        for pred in updated:
            conf_data = pred.get('brazilian_prediction', {}).get('confidence_analysis', {})
            tier = conf_data.get('confidence_tier', 'EXPECTED')
            score = conf_data.get('overall_confidence', 0.60)
            
            tier_counts[tier] = tier_counts.get(tier, 0) + 1
            confidences.append(score)
        
        return {
            'total': len(updated),
            'average_confidence': round(np.mean(confidences), 2),
            'by_confidence_tier': tier_counts,
            'classification_method': 'rank_based_forced_distribution'
        }


# TESTE UNIT√ÅRIO
if __name__ == "__main__":
    print("="*80)
    print("TESTE UNIT√ÅRIO - Dynamic Confidence Engine")
    print("="*80)
    
    # Simular 100 predi√ß√µes com scores id√™nticos (problema atual)
    engine = DynamicConfidenceEngine()
    
    # Cen√°rio 1: Todos 0.60 (problema atual)
    print("\nüìä CEN√ÅRIO 1: Scores id√™nticos (0.60)")
    for i in range(100):
        pred = {
            'brazilian_prediction': {
                'confidence_analysis': {
                    'overall_confidence': 0.60
                }
            },
            'source_patent': {
                'publication_date': f'202{i%5}-01-01',
                'inventors': ['Inv' + str(j) for j in range((i % 5) + 1)]
            }
        }
        engine.add_prediction(pred)
    
    stats = engine.get_statistics()
    print(f"  Average: {stats['average_confidence']}")
    print(f"  Distribution: {stats['by_confidence_tier']}")
    print(f"  Method: {stats.get('classification_method', 'N/A')}")
    
    # Cen√°rio 2: Scores variados
    print("\nüìä CEN√ÅRIO 2: Scores variados")
    engine2 = DynamicConfidenceEngine()
    
    scores_varied = [0.50 + (i/200) for i in range(100)]
    for i, score in enumerate(scores_varied):
        pred = {
            'brazilian_prediction': {
                'confidence_analysis': {
                    'overall_confidence': score
                }
            },
            'source_patent': {
                'publication_date': f'202{i%5}-01-01',
                'inventors': ['Inv' + str(j) for j in range((i % 5) + 1)]
            }
        }
        engine2.add_prediction(pred)
    
    stats2 = engine2.get_statistics()
    print(f"  Average: {stats2['average_confidence']}")
    print(f"  Distribution: {stats2['by_confidence_tier']}")
    print(f"  Method: {stats2.get('classification_method', 'N/A')}")
    
    print("\n‚úÖ Teste completo!")
